% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/main1_evalmod.R
\name{evalmod}
\alias{evalmod}
\title{Evaluate a single model}
\usage{
evalmod(mdat, pscores, olabs, model_name = as.character(NA), data_no = 1L,
  x_interval = 0.001, na.last = FALSE, ties.method = "average",
  olevs = c("negative", "positive"))
}
\arguments{
\item{pscores}{A numeric vector of predicted scores.}

\item{olabs}{A numeric vector or a factor of observed labels.}

\item{model_name}{The name of the model/classifier to be evaluated.}

\item{x_interval}{A numeric value to specifiy an interval of the
x-axis (TPRs for ROC and recall for Precision-Recall).}

\item{na.last}{Passed to \code{\link[base]{rank}} for controlling the
treatment of NAs. The value can be TRUE or FALSE. If TRUE, missing values
in the data are put last; if FALSE, they are put first.}

\item{ties.method}{Passed to \code{\link[base]{rank}} for controlling tied
scores. The value can be "average", "random", or "first". The "first"
method results in a permutation with increasing values at each index
set of ties. The "random" method puts these in random order whereas
the default, "average", replaces them by their mean.}

\item{olevs}{A character vector to overide the levels of the factor for
observed binary labels.}
}
\value{
\code{evalmod} returns a \code{curves} S3 object that
  contains ROC and Precision-Recall curves.
}
\description{
\code{evalmod} takes predicted scores from a model and binary lables
from an observed dataset and calculates ROC and Precision-Recall curves.
}
\examples{
data(P10N10)
curves <- evalmod(pscores = P10N10$scores, olabs = P10N10$labels)
curves
}

